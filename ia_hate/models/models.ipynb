{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8de3fe4a-8871-4a23-af11-059bfd820b0a",
   "metadata": {},
   "source": [
    "### Modelos a entrenar\n",
    "\n",
    "1. Máquinas de soporte vectorial SVM\n",
    "2. Bosques Aleatorios RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2557988b-c059-484a-8564-354e969a35a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics \\\n",
    "import classification_report, recall_score, accuracy_score,precision_score, make_scorer,confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def myConfMatrix(confusion_array,labels,columns):\n",
    "    df = pd.DataFrame(confusion_array, index=labels, columns=columns)\n",
    "    return df\n",
    "\n",
    "def balanceDF(df,labels_dict):\n",
    "    violent = df.loc[df[\"label\"] == labels_dict[\"VIOLENT\"]]\n",
    "    nonviolent = df.loc[df[\"label\"] == labels_dict[\"NONVIOLENT\"]]\n",
    "    violent_patched = violent.sample(nonviolent.shape[0],random_state=0)\n",
    "    #balanced\n",
    "    bdf = pd.concat([violent_patched,nonviolent])\n",
    "    return bdf\n",
    "\n",
    "\n",
    "cm_labels = ['violent', 'nonviolent']\n",
    "cm_columns = ['Predicted violent', 'predicted nonviolent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dffc7ddc-a2ab-45d6-a961-b38abeeca01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "labels_dict = {\n",
    "    \"VIOLENT\": \"violent\",\n",
    "    \"NONVIOLENT\":\"nonviolent\"\n",
    "}\n",
    "\n",
    "df = pd.read_csv(\"../master_data/data.csv\")\n",
    "# mapping label to 1 -> violent 0 -> non-violent\n",
    "df[\"label\"] = df[\"label\"].apply(lambda x: labels_dict[\"VIOLENT\"] if x == 1 else labels_dict[\"NONVIOLENT\"])\n",
    "df['feature'] = df['feature'].str.replace('\\xa0', ' ', regex=False)\n",
    "bdf = balanceDF(df,labels_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d082501b-5b65-45b8-8f57-cf6a8e6bac72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "violent       8689\n",
       "nonviolent    3028\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e87ae17d-3773-4641-98b5-59c4959127bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "violent       3028\n",
       "nonviolent    3028\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdf.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fd09e4-1709-4724-8a36-415e58d21e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49f4a67c-2990-41ac-8d8f-c0bbde8e0e81",
   "metadata": {},
   "source": [
    "Define pipelines, \n",
    "Note df is full dataset and bdf is balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbdd0bc9-1704-4578-a7d8-c8c726e88c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric_features = [\"length\", \"punct\"]\n",
    "categorical_features = [\"feature\"]\n",
    "\n",
    "# numeric_transformer = Pipeline(\n",
    "#     steps=[(\"scaler\", StandardScaler())]\n",
    "# )\n",
    "\n",
    "# categorical_transformer = Pipeline(\n",
    "#     steps=[\n",
    "#         (\"squeeze\", FunctionTransformer(lambda x: x.squeeze(),validate=True)), # make sure you pass a series\n",
    "#         (\"tfidf\",TfidfVectorizer())\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         # (\"num\", numeric_transformer, numeric_features),\n",
    "#         (\"cat\", categorical_transformer, categorical_features)\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"tfidf\", TfidfVectorizer(), \"feature\")  # Apply TfidfVectorizer to the 'feature' column\n",
    "    ]\n",
    ")\n",
    "\n",
    "classifierRF = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\",preprocessor),\n",
    "        (\"rf\",RandomForestClassifier(n_estimators=100,random_state=0,criterion=\"gini\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "classifierSVC = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\",preprocessor),\n",
    "        (\"svc\",svm.SVC(random_state=0))\n",
    "    ]\n",
    ")\n",
    "\n",
    "classifierSVC2 = Pipeline(\n",
    "    [\n",
    "        (\"tfidf\",TfidfVectorizer()),\n",
    "        (\"svc\",svm.SVC(random_state=0))\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "param_grid_svc = {\n",
    "    \"svc__C\": [.1,1, 10, 100],\n",
    "    \"svc__kernel\": ['linear', 'rbf', 'sigmoid'],\n",
    "    \"svc__gamma\": [\"auto\",\"scale\"]\n",
    "}\n",
    "\n",
    "# param_grid_svc = {\n",
    "#     \"svc__C\": [100],\n",
    "#     \"svc__kernel\": ['rbf'],\n",
    "#     \"svc__gamma\": [\"auto\"]\n",
    "# }\n",
    "\n",
    "best_svc = \\\n",
    "GridSearchCV(classifierSVC, param_grid_svc,n_jobs=8,cv=5,\n",
    "             #scoring=\"precision\"\n",
    "             scoring=make_scorer(precision_score,pos_label=labels_dict[\"VIOLENT\"],average=\"binary\",zero_division=0.0)\n",
    ")\n",
    "\n",
    "param_grid_rf = {\n",
    "    'rf__n_estimators': [100, 200, 500],\n",
    "    'rf__max_depth': [None, 10, 20, 30],\n",
    "    'rf__min_samples_split': [2, 5, 10],\n",
    "    'rf__min_samples_leaf': [1, 2, 4],\n",
    "    'rf__max_features': ['sqrt', 'log2'],\n",
    "    'rf__bootstrap': [True, False],\n",
    "    'rf__criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "best_rf = GridSearchCV(classifierRF, param_grid_rf,n_jobs=8,cv=5,\n",
    "                       scoring=make_scorer(precision_score,pos_label=labels_dict[\"VIOLENT\"],average=\"binary\",zero_division=0.0)\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aba5fe02-2db0-44cb-9149-59e8c00f98b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# condition = np.logical_or(bdf[\"feature\"].str.contains(\"robamaridos\"), bdf[\"feature\"].str.contains(\"ella tiene que pedirle permiso\"))\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# print(X.shape)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# X.toarray()\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m transformed_data \u001b[38;5;241m=\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX_train\u001b[49m)\n\u001b[1;32m     14\u001b[0m transformed_data\u001b[38;5;241m.\u001b[39mtoarray()[\u001b[38;5;241m188\u001b[39m,:]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# condition = np.logical_or(bdf[\"feature\"].str.contains(\"robamaridos\"), bdf[\"feature\"].str.contains(\"ella tiene que pedirle permiso\"))\n",
    "\n",
    "\n",
    "# corpus = bdf.loc[condition,[\"feature\"]].squeeze()\n",
    "# print(corpus.head())\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# X = vectorizer.fit_transform(corpus)\n",
    "# print(vectorizer.get_feature_names_out())\n",
    "\n",
    "# print(X.shape)\n",
    "# X.toarray()\n",
    "\n",
    "transformed_data = preprocessor.fit_transform(X_train)\n",
    "transformed_data.toarray()[188,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691f9525-1538-4f73-aca6-8da11c2b60ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62453cf4-3578-4d86-986b-fe5862f21d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094192d8-8877-497c-8ac6-d23cc25f202c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feca3bae-7550-4091-88d9-00969c90a214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03cab17f-8f60-4d1f-b43a-584818cc0dee",
   "metadata": {},
   "source": [
    "## SVC \n",
    "Hyperparameter tuning with both full and balanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dc4824-c0ff-43b3-aa63-19ef557b0d49",
   "metadata": {},
   "source": [
    "#### Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e51ad0c-4c56-4bc8-bdcc-859904ab3f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "train_test_split(data.loc[:,[\"feature\"]],data[\"label\"], test_size= 0.3, random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50eb9713-1882-4a85-a201-46b6fa8d40a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using precission as the Best parameter to evaluate on (CV score=0.915):\n",
      "{'svc__C': 10, 'svc__gamma': 'auto', 'svc__kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  nonviolent       1.00      0.99      0.99      2115\n",
      "     violent       1.00      1.00      1.00      6086\n",
      "\n",
      "    accuracy                           1.00      8201\n",
      "   macro avg       1.00      1.00      1.00      8201\n",
      "weighted avg       1.00      1.00      1.00      8201\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  nonviolent       0.81      0.79      0.80       913\n",
      "     violent       0.93      0.94      0.93      2603\n",
      "\n",
      "    accuracy                           0.90      3516\n",
      "   macro avg       0.87      0.86      0.87      3516\n",
      "weighted avg       0.90      0.90      0.90      3516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_svc.fit(X_train, y_train)\n",
    "print(\"using precission as the Best parameter to evaluate on (CV score=%0.3f):\" % best_svc.best_score_)\n",
    "print(best_svc.best_params_)\n",
    "y_pred_svc = best_svc.predict(X_test)\n",
    "y_pred_svc_train = best_svc.predict(X_train)\n",
    "report_svc_train = classification_report(y_train, y_pred_svc_train)\n",
    "print(report_svc_train)\n",
    "report_svc = classification_report(y_test, y_pred_svc)\n",
    "print(report_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2272c921-6498-45c7-b6d2-589512fd5d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted violent</th>\n",
       "      <th>predicted nonviolent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>violent</th>\n",
       "      <td>2440</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nonviolent</th>\n",
       "      <td>196</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted violent  predicted nonviolent\n",
       "violent                  2440                   163\n",
       "nonviolent                196                   717"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define row and column labels\n",
    "\n",
    "myConfMatrix(confusion_matrix(y_test, y_pred_svc,labels=cm_labels),cm_labels,cm_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bfe192-f367-4913-99c8-3caf0cde1ef3",
   "metadata": {},
   "source": [
    "#### Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "bc9ba988-c2b7-4cec-80d3-074187e4183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bdf\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "train_test_split(data.loc[:,[\"feature\"]],data[\"label\"], test_size= 0.3, random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "356193df-a562-4da3-be00-e5876810a97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using precission as the Best parameter to evaluate on (CV score=0.964):\n",
      "{'svc__C': 100, 'svc__gamma': 'auto', 'svc__kernel': 'rbf'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  nonviolent       0.54      1.00      0.70      2122\n",
      "     violent       0.97      0.14      0.25      2117\n",
      "\n",
      "    accuracy                           0.57      4239\n",
      "   macro avg       0.76      0.57      0.47      4239\n",
      "weighted avg       0.76      0.57      0.47      4239\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  nonviolent       0.55      1.00      0.71       906\n",
      "     violent       0.98      0.20      0.33       911\n",
      "\n",
      "    accuracy                           0.59      1817\n",
      "   macro avg       0.76      0.60      0.52      1817\n",
      "weighted avg       0.77      0.59      0.52      1817\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_svc.fit(X_train, y_train)\n",
    "print(\"using precission as the Best parameter to evaluate on (CV score=%0.3f):\" % best_svc.best_score_)\n",
    "print(best_svc.best_params_)\n",
    "y_pred_svc = best_svc.predict(X_test)\n",
    "y_pred_svc_train = best_svc.predict(X_train)\n",
    "report_svc_train = classification_report(y_train, y_pred_svc_train)\n",
    "print(report_svc_train)\n",
    "report_svc = classification_report(y_test, y_pred_svc)\n",
    "print(report_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "368e523b-5a03-4258-aeac-b86f106a9ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted violent</th>\n",
       "      <th>predicted nonviolent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>violent</th>\n",
       "      <td>178</td>\n",
       "      <td>733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nonviolent</th>\n",
       "      <td>4</td>\n",
       "      <td>902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted violent  predicted nonviolent\n",
       "violent                   178                   733\n",
       "nonviolent                  4                   902"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define row and column labels\n",
    "\n",
    "myConfMatrix(confusion_matrix(y_test, y_pred_svc,labels=cm_labels),cm_labels,cm_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a742d9-b80b-40f1-bb0d-0d438fa3e8cb",
   "metadata": {},
   "source": [
    "#### Comments on balanced vs full:\n",
    "\n",
    "Precision is higher on balanced dataset vs full. .97 > .93, but the loss in recall is gigantic. \n",
    ".20 < .94.  \n",
    "\n",
    "The SVC trained on full data seems to loose a lot of information when balanced, maybe due to the fact that it is being trained on roughly half the data when balanced, and that causes information loss. \n",
    "\n",
    "balanced = 6056 observations\n",
    "full = 11700 observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7c70bb5e-242a-4603-9538-42ae7eb6b53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6056, 4)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493a8d60-1149-40ba-9f48-fbd7e7cb9ef3",
   "metadata": {},
   "source": [
    "## RF\n",
    "\n",
    "Results on Full and Balanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40dd6e9-c772-42c3-8487-a7e298fc5b4a",
   "metadata": {},
   "source": [
    "#### Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "693a8cf7-96bd-4da2-b5c4-92b10cb1e7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "train_test_split(data.loc[:,[\"feature\"]],data[\"label\"], test_size= 0.3, random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "cab863b0-2232-48df-bf6e-044172f036a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pacobahenagaleana/.pyenv/versions/3.9.16/envs/nlpenv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using precission as the Best parameter to evaluate on (CV score=0.884):\n",
      "{'rf__bootstrap': False,\n",
      " 'rf__criterion': 'entropy',\n",
      " 'rf__max_depth': None,\n",
      " 'rf__max_features': 'sqrt',\n",
      " 'rf__min_samples_leaf': 1,\n",
      " 'rf__min_samples_split': 2,\n",
      " 'rf__n_estimators': 100}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  nonviolent       1.00      1.00      1.00      2115\n",
      "     violent       1.00      1.00      1.00      6086\n",
      "\n",
      "    accuracy                           1.00      8201\n",
      "   macro avg       1.00      1.00      1.00      8201\n",
      "weighted avg       1.00      1.00      1.00      8201\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  nonviolent       0.90      0.68      0.77       913\n",
      "     violent       0.90      0.97      0.93      2603\n",
      "\n",
      "    accuracy                           0.90      3516\n",
      "   macro avg       0.90      0.83      0.85      3516\n",
      "weighted avg       0.90      0.90      0.89      3516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_rf.fit(X_train,y_train)\n",
    "print(\"using precission as the Best parameter to evaluate on (CV score=%0.3f):\" % best_rf.best_score_)\n",
    "pprint(best_rf.best_params_)\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "y_pred_rf_train = best_rf.predict(X_train)\n",
    "report_rf_train = classification_report(y_train, y_pred_rf_train)\n",
    "print(report_rf_train)\n",
    "report_rf = classification_report(y_test, y_pred_rf)\n",
    "print(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a6945232-fb1e-4064-912a-21860a6517a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted violent</th>\n",
       "      <th>predicted nonviolent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>violent</th>\n",
       "      <td>2532</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nonviolent</th>\n",
       "      <td>293</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted violent  predicted nonviolent\n",
       "violent                  2532                    71\n",
       "nonviolent                293                   620"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myConfMatrix(confusion_matrix(y_test, y_pred_rf,labels=labels),labels,columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc8d1ab-1993-4cd6-a891-686d3962ecc2",
   "metadata": {},
   "source": [
    "#### Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d9e43064-fad4-4564-9c3a-fb4437ebc4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =\\\n",
    "train_test_split(bdf.loc[:,[\"feature\"]],bdf[\"label\"], test_size= 0.3, random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e0249192-ea32-483c-885d-06d605c1845d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pacobahenagaleana/.pyenv/versions/3.9.16/envs/nlpenv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using precission as the Best parameter to evaluate on (CV score=0.936):\n",
      "{'rf__bootstrap': True,\n",
      " 'rf__criterion': 'entropy',\n",
      " 'rf__max_depth': 30,\n",
      " 'rf__max_features': 'log2',\n",
      " 'rf__min_samples_leaf': 1,\n",
      " 'rf__min_samples_split': 2,\n",
      " 'rf__n_estimators': 500}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  nonviolent       0.89      0.99      0.94      2122\n",
      "     violent       0.99      0.87      0.93      2117\n",
      "\n",
      "    accuracy                           0.93      4239\n",
      "   macro avg       0.94      0.93      0.93      4239\n",
      "weighted avg       0.94      0.93      0.93      4239\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  nonviolent       0.78      0.95      0.86       906\n",
      "     violent       0.94      0.73      0.82       911\n",
      "\n",
      "    accuracy                           0.84      1817\n",
      "   macro avg       0.86      0.84      0.84      1817\n",
      "weighted avg       0.86      0.84      0.84      1817\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_rf.fit(X_train,y_train)\n",
    "print(\"using precission as the Best parameter to evaluate on (CV score=%0.3f):\" % best_rf.best_score_)\n",
    "pprint(best_rf.best_params_)\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "y_pred_rf_train = best_rf.predict(X_train)\n",
    "report_rf_train = classification_report(y_train, y_pred_rf_train)\n",
    "print(report_rf_train)\n",
    "report_rf = classification_report(y_test, y_pred_rf)\n",
    "print(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "3920bf65-e65f-4eb5-acfe-cefa4aac028d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted violent</th>\n",
       "      <th>predicted nonviolent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>violent</th>\n",
       "      <td>669</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nonviolent</th>\n",
       "      <td>43</td>\n",
       "      <td>863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Predicted violent  predicted nonviolent\n",
       "violent                   669                   242\n",
       "nonviolent                 43                   863"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "myConfMatrix(confusion_matrix(y_test, y_pred_rf,labels=labels),labels,columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e22b1a-74ad-4138-b3cc-e769efb1deb4",
   "metadata": {},
   "source": [
    "precision .94, recall is .73 not so good with false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cdab28-2d5f-4c9d-9083-873f3948f6e4",
   "metadata": {},
   "source": [
    "Comment RF Balanced vs Full: \n",
    "\n",
    "comparing balanced to full, precision .94 > .90, recall .73 < .97.  The behavior is consistent with what we observed with SVM.\n",
    "marginal precision comes at a very steep recall cost. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26ef7b5-7a64-477b-a475-477292090a02",
   "metadata": {},
   "source": [
    "Comment RF vs SVM: \n",
    "\n",
    "SVM is slightly better than RF in terms of precision.\n",
    "\n",
    "precision  SVM .93 >  RF. 90  recall SVM .94 < .97"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64312e75-d370-4c54-9d25-67287eda9d4e",
   "metadata": {},
   "source": [
    "Opinion for Giepetto\n",
    "\n",
    "Here's a breakdown of what might be happening with the SVM and Random Forest (RF) models across the imbalanced and balanced datasets, and guidance on what to prioritize given your use case:\n",
    "\n",
    "Key Observations\n",
    "SVM Results:\n",
    "\n",
    "Imbalanced dataset: Precision = 0.93, Recall = 0.94 (Good balance between precision and recall)\n",
    "\n",
    "Balanced dataset: Precision = 0.97, Recall = 0.20 (High precision but very low recall)\n",
    "\n",
    "Why?:\n",
    "\n",
    "With the balanced dataset, SVM is likely overfitting to the violent class because it now treats the violent and nonviolent classes equally, even though nonviolent is less common in the real-world distribution.\n",
    "This causes the model to become more conservative, predicting the violent label only when it's very confident, leading to high precision but poor recall.\n",
    "Random Forest Results:\n",
    "\n",
    "Imbalanced dataset: Precision = 0.90, Recall = 0.97 (Slight bias toward recall)\n",
    "\n",
    "Balanced dataset: Precision = 0.94, Recall = 0.73 (More balanced precision-recall tradeoff)\n",
    "\n",
    "Why?:\n",
    "\n",
    "RF handles imbalance better than SVM, especially with the imbalanced dataset, because it can inherently deal with class distributions using its splitting criteria (e.g., Gini or entropy).\n",
    "On the balanced dataset, RF becomes slightly more conservative, improving precision but reducing recall compared to the imbalanced dataset.\n",
    "What to Prioritize?\n",
    "Given that false positives (nonviolent classified as violent) are more critical than false negatives (violent classified as nonviolent), precision is more important in your case.\n",
    "\n",
    "However, you also need an acceptable level of recall to ensure the model isn't ignoring too many violent instances.\n",
    "\n",
    "Dataset Choice\n",
    "Imbalanced Dataset:\n",
    "\n",
    "Better represents the real-world distribution.\n",
    "Produces models with higher recall and acceptable precision (RF: 0.90/0.97; SVM: 0.93/0.94).\n",
    "Recommended if the goal is to generalize to real-world scenarios without resampling artifacts.\n",
    "Balanced Dataset:\n",
    "\n",
    "Useful if you want to emphasize precision (e.g., with SVM: 0.97 precision), but at the cost of significantly lower recall.\n",
    "May not represent the natural data distribution and could lead to suboptimal performance on real-world data.\n",
    "Model Choice\n",
    "Random Forest seems to be performing more consistently across both datasets:\n",
    "\n",
    "On the imbalanced dataset, RF achieves high recall (0.97) with decent precision (0.90).\n",
    "On the balanced dataset, RF strikes a better balance (0.94 precision, 0.73 recall) compared to SVM.\n",
    "RF's ability to handle imbalance natively makes it a robust choice, especially if you focus on imbalanced data.\n",
    "SVM, while achieving higher precision on the balanced dataset (0.97), suffers from extremely low recall (0.20), which may not be acceptable for detecting violent cases.\n",
    "\n",
    "Recommendation\n",
    "Use the imbalanced dataset with Random Forest:\n",
    "\n",
    "Precision = 0.90, Recall = 0.97\n",
    "This combination ensures you capture most violent cases (high recall) while keeping false positives (nonviolent misclassified as violent) relatively low.\n",
    "Consider threshold adjustment:\n",
    "\n",
    "For RF, adjust the decision threshold to further fine-tune the precision-recall tradeoff based on your specific requirements.\n",
    "Monitor real-world performance:\n",
    "\n",
    "Test the selected model on a held-out or real-world dataset to confirm it performs well on the expected distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ab36e9-f002-416b-8017-b7474dcc3cc1",
   "metadata": {},
   "source": [
    "If you're uncertain about the real-world prevalence of hate speech, here are strategies to handle this ambiguity:\n",
    "\n",
    "1. Balanced Dataset for Training\n",
    "Using the balanced dataset (e.g., 3000 hate speech and 3000 non-hate speech) might help avoid biasing the model toward hate speech and result in a more conservative classifier.\n",
    "While this might slightly under-detect hate speech (lower recall), it aligns better with your goal of minimizing false positives.\n",
    "2. Imbalanced Dataset with Class Weighting\n",
    "Train on the full imbalanced dataset but apply class weighting to penalize misclassifications of non-hate speech more heavily.\n",
    "Example with Scikit-learn:\n",
    "python\n",
    "Copy code\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    class_weight={'violent': 1, 'nonviolent': 2},  # Adjust weights to penalize nonviolent misclassification more\n",
    "    random_state=42\n",
    ")\n",
    "3. Threshold Adjustment\n",
    "Even with an imbalanced dataset, you can adjust the decision threshold for the hate speech class to prioritize precision. This reduces the likelihood of false positives.\n",
    "4. External Validation\n",
    "Validate your model on a separate dataset (if available) that reflects a more typical distribution of hate vs. non-hate speech to ensure generalizability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579b5bf1-74f1-45ab-bb82-fbdeb04c8f16",
   "metadata": {},
   "source": [
    "Given the fact that the full dataset is very imbalanced. we will compare both best models on an identical test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fd7c68-dbfb-49ce-89d9-55494e11af9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid_rf = {\n",
    "#     \"rf__C\": [1, 10, 100],\n",
    "#     \"rf__kernel\": ['linear', 'rbf', 'sigmoid'],\n",
    "#     \"rf__gamma\": [\"auto\",\"scale\"]\n",
    "# }\n",
    "\n",
    "param_grid_rf = {\n",
    "    'rf__n_estimators': [100, 200, 500],\n",
    "    'rf__max_depth': [None, 10, 20, 30],\n",
    "    'rf__min_samples_split': [2, 5, 10],\n",
    "    # 'min_samples_leaf': [1, 2, 4],\n",
    "    # 'max_features': ['sqrt', 'log2'],\n",
    "    # 'bootstrap': [True, False],\n",
    "    # 'criterion': ['gini', 'entropy']\n",
    "}\n",
    "best_rf = GridSearchCV(classifierRF, param_grid_rf,n_jobs=8,cv=5,scoring=make_scorer(precision_score,pos_label=VIOLENT,average=\"binary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8a7bdb-e0da-46c6-8489-4db0d3e775fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18c9466-291c-47ef-9ed3-eca58683299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf.fit(X_train,y_train)\n",
    "print(\"using precission as the Best parameter to evaluate on (CV score=%0.3f):\" % best_rf.best_score_)\n",
    "pprint(best_rf.best_params_)\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "y_pred_rf_train = best_rf.predict(X_train)\n",
    "report_rf_train = classification_report(y_train, y_pred_rf_train)\n",
    "print(report_rf_train)\n",
    "report_rf = classification_report(y_test, y_pred_rf)\n",
    "print(report_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5c80dc-0db3-4c3e-84b0-60eca4f68bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "oneTest = pd.DataFrame(pd.Series([\n",
    "    \"Las mujeres pertenencen en la cocina, y la lavandería\",\n",
    "    \"Casarse es la función de una mujer\",\n",
    "    \"El amor es lo mas puro\",\n",
    "    \"texto lucha amor\"\n",
    "]),columns=[\"feature\"])\n",
    "best_svc.predict(oneTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d22896-605c-45e0-8496-a0bc38789176",
   "metadata": {},
   "source": [
    "Revisemos ahora el desempeño del modelo sin cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d1e31a34-1335-46d2-b959-5869bdb8ef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\"feature\"]\n",
    "\n",
    "# numeric_transformer = Pipeline(\n",
    "#     steps=[(\"scaler\", StandardScaler())]\n",
    "# )\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"squeez\", FunctionTransformer(lambda x: x.squeeze())), # make sure you pass a series\n",
    "        (\"tfidf\",TfidfVectorizer())\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "classifierSVC = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"svc\",svm.SVC(random_state=0))\n",
    "    ]\n",
    ")\n",
    "\n",
    "classifierSVC2 = Pipeline(\n",
    "    [\n",
    "        (\"tfidf\",TfidfVectorizer()),\n",
    "        (\"svc\",svm.SVC(random_state=0))\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d3b543-2f4a-4570-8f94-6787b4fc72b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c454e8c-f2f9-43c9-84ea-f767461a3988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73dc329-ac04-4602-be9b-0574dcbec0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_svc_simple = classifierSVC2.fit(X_train.squeeze(),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae7e730-05b1-4a94-a48a-f3192852098d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34168552-3744-4d41-bb7b-db45604d518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mod_svc_simple.predict(X_test.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ad46d8-38e5-4013-a271-29090373cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2085205d-74a8-45c3-ba51-18df3ed70b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "pprint(report[VIOLENT])\n",
    "pprint(report[NONVIOLENT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bc0c65-95f0-4e15-a08c-f36c0398d791",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3d2e61-bd4b-415f-9e6b-bc7636b4d20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
